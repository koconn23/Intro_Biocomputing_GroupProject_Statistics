---
title: "Statistics Group Project Using R"
author: "Libby Fortin (efortin@nd.edu), Keith O'Connor (koconn23@nd.edu), Chelsea Weibel (cweibel@nd.edu)"
date: "11/27/2017"
output: html_document
---

### Question 1: Evaluating the effect of three different new antibiotics on growth of E. coli in lab cultures.
##### Let's visualize the data using ggplot. Since the data is categorical we use a boxplot:
```{r}

library(ggplot2)

antibiotics <- read.csv("antibiotics.csv")
      
plot1 <- ggplot(antibiotics, aes(x = trt, y = growth)) +
      geom_boxplot() + 
      theme_bw() + 
      xlab("Antibiotic Type") + ylab("E. coli Growth") +
      theme(plot.title = element_text(hjust = 0.5)) + # Centers the title
      ggtitle("Different Antibiotics on Growth")
                        
plot1

```

#### Next, we need to look at antibiotic treatments on the growth of E. coli using an ANOVA-design linear model and likelihood ratio test. (11/29/17)
##### To do this we first need to assign a value to the absence of antibiotic treatment and the presence of antibiotic treament
+ The easiest way to do this is with a for-loop that assigns a zero to the control treatment, and a one to any of the antibiotic treatments
+ The for-loop below adds a column to the antibiotics dataset called 'aborct' entering zeros and ones to antibiotic treatment or no antibiotic treatment

```{r}
for (i in 1:nrow(antibiotics)){
  if (antibiotics$trt[i] == 'control'){
    antibiotics$aborct[i] <- 0
  }
  else{
    antibiotics$aborct[i] <- 1
  }
}
```

##### Next we need to subset the data into matrices that contain only the control data and one of the antibiotic treatments
+ These matrices are labeled ab1, ab2, and ab3 for the different types of antibiotics
```{r}
ab1 <- antibiotics[antibiotics$trt == 'control',]
ab1[5:8,] <- antibiotics[antibiotics$trt == 'ab1',]
ab2 <- antibiotics[antibiotics$trt == 'control',]
ab2[5:8,] <- antibiotics[antibiotics$trt == 'ab2',]
ab3 <- antibiotics[antibiotics$trt == 'control',]
ab3[5:8,] <- antibiotics[antibiotics$trt == 'ab3',]
```

##### It's easiest to keep our results of the negative log likelihood models and the likelihood ratio test organized if we create a matrix that holds all the results
+ Below we create a matrix where column 1 holds the results of the null model, column 2 holds the results of the linear model, and column 3 holds the results of the likelihood ratio test
```{r}
results <- matrix(0,3,3)
colnames(results) <- c("null", "linear", "chisq")
```

##### Now we are ready to define our negative log likelihood functions, one for the null model and one for the linear model
+ The null model hypothesizes that there is no relationship between antibiotics and growth
+ The linear model hypothesizes that there is a linear relationship between antibiotics and growth
```{r}
#Null model function
nllnull <- function(p,y){
  B0=p[1]
  sig=exp(p[2])
  expected=B0
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}

#Linear Model function
nlllinear <- function(p,x,y){
  B0=p[1]
  B1=p[2]
  sig=exp(p[3])
  expected=B0+B1*x
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}
```

##### We are ready to run the null and linear negative log likelihood models for the three different antibiotic treatments and store them in our results table
```{r}
# Antibiotic 1 null model and linear model results
initialGuess <- c(1,1)
fit <- optim(par=initialGuess,fn=nllnull,y=ab1$growth)
results[1,1] <- fit$value

initialGuess <- c(1,1,1)
fit <- optim(par=initialGuess,fn=nlllinear,x=ab1$aborct,y=ab1$growth)
results[1,2] <- fit$value

# Antibiotic 2 null model and linear model results 
initialGuess <- c(1,1)
fit <- optim(par=initialGuess,fn=nllnull,y=ab2$growth)
results[2,1] <- fit$value

initialGuess <- c(1,1,1)
fit <- optim(par=initialGuess,fn=nlllinear,x=ab2$aborct,y=ab2$growth)
results[2,2] <- fit$value

# Antibiotic 3 null model and linear model results
initialGuess <- c(1,1)
fit <- optim(par=initialGuess,fn=nllnull,y=ab3$growth)
results[3,1] <- fit$value

initialGuess <- c(1,1,1)
fit <- optim(par=initialGuess,fn=nlllinear,x=ab3$aborct,y=ab3$growth)
results[3,2] <- fit$value
```

##### Finally we calculate the likelihood ratio test and store the results in our results table
```{r}
#likelihood ratio test results
A <- 2*(results[1,1]-results[1,2])
B <- 2*(results[2,1]-results[2,2])
C <- 2*(results[3,1]-results[3,2])
results[1,3] <- pchisq(q=A, df=1, lower.tail=FALSE) 
results[2,3] <- pchisq(q=B, df=1, lower.tail=FALSE) 
results[3,3] <- pchisq(q=C, df=1, lower.tail=FALSE)
results
```
##### All of the antibiotic treatments have a significant effect on growth because the chi squared values are all less than 0.05!


### Question 2: Evaluating the effect of sugar concentration on growth of E. coli in lab cultures.

##### Let's visualize the data using ggplot. Since the data is continuous we use a linear plot. We can also add the linear equation and R^2^ value to the graph to tell us more about the data.
```{r}
#### Linear plot of sugar effects on growth with line equation and R2 ####

library(ggplot2)

sugardata <- read.csv(file = "sugar.csv", header=TRUE) # Importing the data

# Graphing the data
plot2 <- ggplot(data = sugardata, aes(x = sugar, y = growth))+
  geom_point(color = "blue1", shape = 16, size = 2) +
  theme_classic() +
  xlab("Sugar Concentration") + ylab("E. coli Growth") +
  ggtitle("Effect of Sugar Concentration on Growth of E. coli") +
  theme(plot.title = element_text(hjust = 0.5)) + #Centers the title
  stat_smooth(method = "lm", se=FALSE, color="black") + #Adds a trend line, se=FALSE gets rid of cloud around trendline.
  geom_text(aes(x = 5, y = 25, label = lm_eqn1(lm(sugar ~ growth, sugardata))), parse = TRUE) # Adds the values for the R2 value and equation of the trendline to the coordinates x and y


# Adding the trendline, equation, and R2 value to the graph
m= lm(sugar ~ growth, sugardata)

lm_eqn1 = function(m) {       #Function to calculate and add R2 value and equation of the trendline to plot
  
  l <- list(a = format(coef(m)[1], digits = 2),
            b = format(abs(coef(m)[2]), digits = 2),
            r2 = format(summary(m)$r.squared, digits = 3));
  
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }
  
  as.character(as.expression(eq));                 
}

plot2

```

#### Next, we need to test for an effect of sugar concentration on growth of E. coli using a regression-design linear model and likelihood ratio test.

Our null hypothesis is that the growth of the E. coli is the same regardless of the sugar concentration.

```{r}
############## Null model

nllnull = function(p,y){
  B0=p[1]
  sig=exp(p[2])
  expected=B0
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}

initialGuess = c(5,1)
null = optim(par=initialGuess,fn=nllnull,y=sugardata$growth)

```

Our alternative hypothesis is that the growth of the E. coli is dependent on the sugar concentration.

```{r}
################ Linear Model

nllike_linear=function(p,x,y){
  B0=p[1]
  B1=p[2]
  sigma=exp(p[3])
  
  expected=B0+B1*x
  
  nll_linear=-sum(dnorm(x=y,mean=expected,sd=sigma,log=TRUE))
  return(nll_linear)
}

initialGuess=c(5,1,1)
fit_linear=optim(par=initialGuess,fn=nllike_linear,x=sugardata$sugar,y=sugardata$growth)

```

Next, we coducted a likelihood ratio test to determine which model fit the data better.

```{r}

############# likelihood ratio test
q = 2*(null$value-fit_linear$value)
lrt = pchisq(q=q, df=1, lower.tail=FALSE)
print(lrt)
```

Becuase the p-value is less than 0.05 (2.64e-10), this means that we can reject the null hypothesis and conclude that there is a significant effect of sugar concentration on E. coli growth



### Statistical Power Analysis

## Regression-designed Experiment

First, we randomly selected 24 x-values between 0-50 and calculated the corresponding y-values based on a linear equation. We ran 10 monte carlos of this data. We then added noise to the data with 8 sigma values between 1 and 24.

```{r}
size = 24 # Creates a random generation of 24 x-values between 0 and 50 

num_sims <- 10 # Simulate the data 10 times 
n_per_sim <- 24 # Each simulation will have 24 values
set.seed(24) # Seed is necessary for reproducibility 
sigma_num <- 8 # The amount of sigma values for this analysis
sigma <- c(1,2,4,6,8,12,16,24) # Setting the sigma values for this analysis

outputx<-as.data.frame(matrix(0, ncol=10, nrow=24)) # Empty matrix to compile the 10 reiterations of the 24 randomly generated x variables
outputy<-as.data.frame(matrix(0, ncol=10, nrow=24)) # Empty matrix to compile the 10 reiterations of the 24 y variables
youtput <-list() # Empty file to compile the output matrices into a list
for(sigma_number in 1:sigma_num){
  youtput[[sigma_number]]=matrix(NA,24,num_sims)
}

###### For loop to randomly generate x-values and then corresponding y-values based on the provided slope and intercept

for (sim_number in 1:num_sims){ # This starts your for loop
  x = sample(x = 0:50, size = 24) # 24 randomly generates x-values between 0 and 50
  outputx[,sim_number] <- x # Puts the randomly generated x-values with 10 iterations into empty matrix created before the for-loop 
  m <- 0.4 # Given slope value
  b <- 10 # Given y-intercept
  y = m*x + b # Calculates y-values from the 24 randomly generated x-values using given slope and intercept 
  outputy[,sim_number] <- y # Puts the y-values with 10 iterations into empty matrix created before the for-loop 
}

###### For loop to add noise to the y-values based on the sigma values given

  for (sigma_number in 1:sigma_num){
    for (j in 1:10){
  youtput[[sigma_number]][,j] = outputy[,j] + rnorm(nrow(outputy), mean=0, sd=sigma[sigma_number])
    }
  }
```

Next, we ran our data through a null model.

```{r}

#Null model function

null.value.mat <- matrix(NA,8,10)
null.par.mat <- array(NA,dim = c(2,8,10))

nllnull <- function(p,y){
  B0=p[1]
  sig=exp(p[2])
  expected=B0
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}

for(sigma_number in 1:8){
    for(num_sims in 1:10){
        initialGuess = c(2,10)
        null = optim(par=initialGuess,fn=nllnull,
                     y=as.matrix(youtput[[sigma_number]][,num_sims]))

        null.value.mat[sigma_number,num_sims] <- null$value

        null.par.mat[,sigma_number,num_sims] <- null$par
    }
}
```

Then, we ran our data through a linear model.

```{r}

#Linear Model function

linear.value.mat <- matrix(NA,8,10)
linear.par.mat <- array(NA,dim = c(3,8,10))

nlllinear <- function(p,x,y){
  B0=p[1]
  B1=p[2]
  sig=exp(p[3])
  expected=B0+B1*x
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}

for(sigma_number in 1:8){
    for(num_sims in 1:10){
        initialGuess = c(0,0.3,2)
        linear = optim(par=initialGuess,fn=nlllinear, x=as.matrix(outputx[,num_sims]),
                     y=as.matrix(youtput[[sigma_number]][,num_sims]))

        linear.value.mat[sigma_number,num_sims] <- linear$value

        linear.par.mat[,sigma_number,num_sims] <- linear$par
    }
}
```

We then performed a likelihood ratio test to determine if there was a significant difference in the fit between our null and linear models.

```{r}
####### Likelihood ratio test

lrt.value <- matrix(NA,8,10) # Empty matrix to store the p-values

for(sigma_number in 1:8){ # Start of for loop 1
    for(num_sims in 1:10){ # Start of for loop 2
      
      q = 2*(null.value.mat[sigma_number,num_sims]-linear.value.mat[sigma_number,num_sims]) # Calculating the q-value for each cell - subtracting the linear value from the null value and multiplying by 2
      lrt = pchisq(q=q, df=1, lower.tail=FALSE) # Conducting the likelihood ratio test
      lrt.value[sigma_number,num_sims] <- lrt # Storing the outputs from the likelihood ratio test in the matrix that was created earlier
    }
  }

# Average p-value across monte carlos
for (sigma_number in 1:8){
  print(mean(lrt.value[sigma_number,]))
}
```
The p-values are significnat until we get to the sixth sigma value (sigma=12).



## ANOVA-designed Experiment

# 2-level ANOVA

First we set our two experimental trials to be 12 replicates at an x-value of 13 and 12 replicates at an x-value of 38. We then calculated our y-values from a linear equation and added some noise to the data with 8 sigma values between 1 and 24.

```{r}
## 2-level ANOVA ##
x2 = c(13,13,13,13,13,13,13,13,13,13,13,13,38,38,38,38,38,38,38,38,38,38,38,38)
x_values2 = matrix(rep(x2,10),nrow=24,ncol=10)

y2 <-  .4 * x_values2 + 10

youtput2 <-list()
for(sigma_number in 1:sigma_num){
  youtput2[[sigma_number]]=matrix(NA,24,num_sims)
}

for (sigma_number in 1:8){
  for (num_sims in 1:10){
  youtput2[[sigma_number]][,num_sims] = y2[,num_sims] + rnorm(nrow(y2), mean=0, sd=sigma[sigma_number])
    }
}

```

We then categorized our x-values to be 0 and 1. x=13 became 0 (as the control) and x=38 became 1 (as the treatment).

```{r}

for (i in 1:nrow(x_values2)){
  for(j in 1:ncol(x_values2)){
  if (x_values2[i,j] == '13'){
    x_values2[i,j] <- 0
  }
  else{
    x_values2[i,j] <- 1
  }
 }
}

```

We created output matrices and arrays to store the results from our likelihood ratio test

```{r}

# Output matrices/arrays for null model values
A2.null.value.mat <- matrix(NA,8,10)
A2.null.par.mat <- array(NA,dim = c(2,8,10))
A2.linear.value.mat <- matrix(NA,8,10)
A2.linear.par.mat <- array(NA,dim = c(3,8,10))

```

Then we created custom functions - a null and a linear - that we used for our analysis.

```{r}

# Null function
nllnull <- function(p,y){
  B0=p[1]
  sig=exp(p[2])
  expected=B0
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}

# Linear function
nlllinear <- function(p,x,y){
  B0=p[1]
  B1=p[2]
  sig=exp(p[3])
  expected=B0+B1*x
  nll=-sum(dnorm(x=y, mean=expected, sd=sig,log=TRUE))
  return(nll)
}

```

Next, we ran the models.

```{r}

### Null model
for(sigma_number in 1:8){
    for(num_sims in 1:10){
        initialGuess = c(1,10)
        null = optim(par=initialGuess,fn=nllnull,
                     y=as.matrix(youtput2[[sigma_number]][,num_sims]))

        A2.null.value.mat[sigma_number,num_sims] <- null$value

        A2.null.par.mat[,sigma_number,num_sims] <- null$par
    }
}

### Linear model for rows 1-12 (test value = 13)
for(sigma_number in 1:8){
    for(num_sims in 1:10){
        initialGuess = c(0,0,2)
        linear = optim(par=initialGuess,fn=nlllinear, x=as.matrix(x_values2[,num_sims]),
                     y=as.matrix(youtput2[[sigma_number]][,num_sims]))

        A2.linear.value.mat[sigma_number,num_sims] <- linear$value

        A2.linear.par.mat[,sigma_number,num_sims] <- linear$par
    }
}

```

We then conducted a likelihood ratio test between the linear model of our two x-values (13 and 38) to determine if there was a significant differnece between the two treatments.

```{r}
#### Comparing the two trial values (13 vs 38)
lrt.value.A2 <- matrix(NA,8,10) # Empty matrix to store the p-values

for(sigma_number in 1:8){ # Start of for loop 1
    for(num_sims in 1:10){ # Start of for loop 2
      
      q = 2*(A2.null.value.mat[sigma_number,num_sims]-A2.linear.value.mat[sigma_number,num_sims]) # Calculating the q-value for each cell - subtracting the linear value from the null value and multiplying by 2
      lrt = pchisq(q=q, df=1, lower.tail=FALSE) # Conducting the likelihood ratio test
      lrt.value.A2[sigma_number,num_sims] <- lrt # Storing the outputs from the likelihood ratio test in the matrix that was created earlier
    }
  }

# Average p-value across monte carlos
for (sigma_number in 1:8){
  print(mean(lrt.value.A2[sigma_number,]))
}
```
The p-values are significnat until we get to the sixth sigma value (sigma=12).


# 4-level ANOVA

First we set our four experimental trials to be 10, 20, 30, and 40. Each trial was replicated six times for each monte carlo replicate. We then calculated our y-values from a linear equation and added some noise to the data with 8 sigma values between 1 and 24.

```{r}

## 4-level ANOVA ##
x4 = c(10,10,10,10,10,10,20,20,20,20,20,20,30,30,30,30,30,30,40,40,40,40,40,40)
x_values4 = matrix(rep(x4,10),nrow=24,ncol=10)


y4 <- .4 * x_values4 + 10

outputy4 <-as.data.frame(matrix(0, ncol=10, nrow=24))
youtput4 <-list()

for (sigma_number in 1:sigma_num){
  outputy4 = y4 + rnorm(length(y4), mean=0, sd=sigma[sigma_number])
  
  youtput4[[sigma_number]] <- outputy4
}
```

# 8-level ANOVA

First we set our eight experimental trials to be 5, 10, 15, 20, 25, 30, 35, 40. Each trial was replicated three times for each monte carlo replicate. We then calculated our y-values from a linear equation and added some noise to the data with 8 sigma values between 1 and 24.

```{r}
## 8-level ANOVA ##
x8 = c(5,5,5,10,10,10,15,15,15,20,20,20,25,25,25,30,30,30,35,35,35,40,40,40)
x_values8 = matrix(rep(x8,10),nrow=24,ncol=10)

y8 <- .4 * x_values8 + 10

outputy8 <-as.data.frame(matrix(0, ncol=10, nrow=24))
youtput8 <-list()

for (sigma_number in 1:sigma_num){
  outputy8 = y8 + rnorm(length(y8), mean=0, sd=sigma[sigma_number])
  
  youtput8[[sigma_number]] <- outputy8
}

```






